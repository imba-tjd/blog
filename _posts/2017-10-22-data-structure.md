---
title: 数据结构
---

一部分参见 https://github.com/imba-tjd/C-Code-Archives/blob/master/数据结构/知识笔记.md

## 树

### 基本术语

* 树的结点(根结点)：包含一个数据元素及若干指向子树的分支
* 孩子结点(子结点)：结点的子树的根称为该结点的孩子。子孙结点：以某结点为根的子树中任一结点都称为该结点的子孙
* 双亲结点(父结点)。祖先结点：从根到该结点的所经分支上的所有结点
* 兄弟结点：父结点相同的结点。堂兄结点：同一层上的结点
* 结点的层次：根结点的层定义为1。根的孩子为第二层结点，依此类推
* 树的深度：树中最大的结点层
* 结点的度：结点的孩子的个数。树的度：树中结点最大的度数
* 叶子结点(终端结点)：度为0的结点。分支结点(内部结点)：度不为0的结点
* 有序树：子树有序的树，如 家族树、二叉树
* 森林：互不相交的树集合。森林和树的联系：一棵树去掉根，其子树构成一个森林；一个森林增加一个根结点成为树
* 路径：两个结点（含）之间经过的结点序列。结点的路径长度：路径中边的个数。树的路径长度：各结点路径长度之和

### 性质

* 结点总数 = (分支总数/边总数/各结点的度数之和)+1 = 各个度数结点的数量之和，即N=1+N1+2N2(+3N3)=N0+N1+N2(+N3)
* 度为m的树中第i层上最多有m^(i-1)个结点，i>=1
* 高度为h的m叉树最多有(m^h-1)/(m-1)个结点，由等比数列求和推导；至少有h+m-1个结点，画图容易理解，一条竖线仅有最下面分支
* 具有n个结点的m叉树的最小高度：logm(n*(m-1)+1)向上取整，就是上一条解出h；直接画图也不难
* 满m叉树中结点i的第一个孩子的编号：(i-1)*m+2
* 只具有叶子结点和度为m结点的m叉树（正则k叉树），叶子结点个数与非叶子结点个数的关系：见哈夫曼树
* 树和森林转换成二叉树：孩子兄弟法
  * 对于某个结点，保留第一个孩子为新二叉树的左孩子，其余的孩子不用管，把右兄弟作为右孩子；实际上是对第一个结点的所有孩子和兄弟分别递归调用此方法，再作为左右孩子
  * 画法上是把兄弟横着连起来，然后顺时针转45度
  * 一棵树转换后根结点没有右子树，森林转换后才有
  * 这种转换的结果是唯一的
  * 若原有n个非叶子结点，则转换后有n+1个结点右指针为空，来自于每个非叶子结点的最后一个孩子加上[最后一个(若为森林)]根结点
  * 若原有n个叶子结点，则转换后有n个结点左指针为空

### 实现

* 双亲表示法：{ data, parent } 可用数组存储
* 孩子表示法：{ data, childs } 不方便用数组因为孩子长度不确定，可用单链表
* 孩子兄弟法（即二叉树表示法）：{ data, firstchild, nextsibling }

## 二叉树

### 性质

* 第i层上最多有2^(i-1)个结点
* N0=N2+1，N=N1+2N2+1。满二叉树N1为0，完全二叉树N1为0或1
* 满二叉树(Perfect BT)：高度为h的二叉树，结点数为(2^h)-1，也是能有的最多的结点；国外的满二叉树是Full BT，指没有度为1的结点，国内的严格来说应该叫完美二叉树
* 扩展二叉树：把空结点都用值为`.`的叶子补齐，变成满二叉树
* 与度为2的有序树的区别：二叉树即使某结点只有一个子结点也要分左右，前者不用；二叉树的度不超过2即可，可为空，而前者至少要有三个结点
* 设二叉树有2n个结点，m < n，则不可能存在 2m个度为1 的结点。因为根据计算n1=2(n-n2)-1，是奇数
* 由n个结点能构成的二叉树的个数、只知先序序列也一样：卡特兰数(出栈次序问题)
* 没有度为1的结点，高度为h的二叉树，结点数最少为：2h-1。即第一层只有根结点，其余每一层都是两个结点。另见哈夫曼树
* 数组的实现
  * 结点N的父结点是N/2，左孩子是2N，右孩子是2N+1；如果N是偶数，它是父结点的左孩子，否则为右孩子。但这样根结点索引需要从1开始
  * 若要从0开始，结点N的父结点是(N+1)/2-1，左孩子是2N+1，右孩子是2N+2

### 完全二叉树(Complete BT)

* 只有最后一行的后面一部分可以没有结点
* 具有n个结点的完全二叉树或满二叉树的高度：log2(n)向下取整+1，或log(n+1)向上取整
* n/2向下取整及其前面的结点全部是分支结点，其余的为叶子结点
* 如果有度为1的结点，只能有一个且就是最后一个分支结点，且此时n为偶数；n为奇数则所有分支结点的度都为2
* 某一层有几个叶子结点，则该CBT结点数量最少的情形是该层就是最后一层，且仅有这几个结点。结点数最多的情形是这是倒数第二层，这些叶子结点在最右边，它们的左兄弟在下一层排满两个孩子。若指定高度，则结点最少时为最后一层只有一个，最多时为满二叉树

### 线索二叉树

* 中序线索二叉树某个结点的前驱/后继就是它中序遍历的前面/后面那个结点
* 添加ltag和rtag标识是前驱(1)还是孩子(0)。如果有孩子，则前驱是左子树最右边的结点，后继是右子树最左边的结点，注意无需也不一定是叶子结点
* 树是逻辑结构，但线索二叉树是一种物理/存储结构且不是逻辑结构
* 普通二叉树中，空指针数 = 2N0+N1 = N+1，线索二叉树就是利用上了这些。非空指针数 = 分支数 = N-1
* 中序线索二叉树最左边和最右边的指针可以为null也可指向根结点，根据题意即使是null也可能算作线索。先序和后序分别只有最右边和最左边的为null；如果先序的根结点无左子树，则又要多一个null
* 先序和中序线索二叉树，分别先序和中序遍历它们不再需要栈；但后序遍历后序线索二叉树仍需要栈
  * 另一种说法：在先序(后序)线索二叉树中查找一个结点的先序后继(后序前驱)很简单，但查找先序前驱(后序后继)必须知道双亲结点，仍无法有效查找
* 先序线索二叉树的后继：如果有左孩子，则左孩子就是其后继；如果无左孩子且有右孩子，则右孩子就是其后继；这两条与非线索的一样；如果无孩子，则右指针是后继
* 构造方式：遍历前准备一个pre指针，先递归处理左孩子，再处理自己，如果没有左孩子就把pre的后继设为自己，自己的前驱设为pre，把自己赋给pre，再递归处理右孩子
* 画图方式：把树画出来，把想要的那一种遍历结果写出来，按遍历结果依次把两个结点之间的空指针互相指向

### 遍历

* 先序遍历：先访问自己，然后是左孩子，然后右孩子；中序遍历、后序遍历略。这三种遍历，叶子结点的先后顺序完全相同，因为要求先左孩子后右孩子
* 树的先根遍历等于其对应二叉树表示的的先序遍历，后根遍历等于中序遍历
* 层次遍历：按数组的顺序访问，对于链表树要用队列辅助；本来就是非递归的
* 非递归中序遍历
  1. 循环，当p不为null时，入栈，p=p->lchild（一路向左）
  2. else出栈并访问p（此时栈可以为空），然后p=p->rchild
  3. 循环条件是p不为null或栈非空（栈空时右孩子可能不为null）
  4. 思路是只管自己，孩子是否为null不管
  5. 如果是先序遍历，入栈前访问p即可
* 非递归后序遍历
  1. 还是p不为null时入栈走左边，为null时出栈
  2. （在结点属性中）要加一个flag记录是否走完了右孩子，出栈时检查
  3. 如果为false，改为true后再压栈p，p=p->rchild，下一次出来时就为true了
  4. 如果为true，访问自己后把p=null即可
  5. 或在最外面放个指针指向最近访问的结点
* 由遍历序列构造二叉树
  * 根据一棵树的 先序和中序序列 或者 后序和中序序列 可唯一地确定一颗二叉树，第一个(最后一个)一定是根结点，到中序序列里找相同的字母就能分出左子树和右子树，反复继续即可
  * 层次和中序序列也可确定
  * 如果只知道先序和后序序列，无法确定树，只能确定祖先关系：先序XY，后序YX，则X是Y的祖先，但Y可能是左孩子也可能是右孩子。如果没有度为1的结点则可以确定，如满二叉树
* 如果一个叶子结点是二叉树中某个子树中序遍历结果的最后一个，则它一定也是该子树先序遍历结果的最后一个。其余几种情况可用根结点+左孩子两个结点的反例判断
* 如果一颗非空的二叉树先序遍历和后序遍历的序列正好相反，则该二叉树一定只有一个叶子结点，结点数与高度相同，即单支树，这样的树有2*(h-1)种，因为左右孩子有区别。先序和后序相同，则只有根结点。先序和中序相同，非叶结点只有右子树
* 非递归层次遍历求树的深度：根入队；当队列不为空时，出队列，左右孩子入队列；有一个last记录每一层的最后一个结点，当front==last时，层数加一，last=rear（因为此时队列里有且仅有下一层的所有结点）
* 若m是n的祖先，求m到n的路径用：后序遍历

## 并查集

一种简单的集合表示，支持以下操作：

1. Union(S, Root1, Root2)：S[Root2]=Root1，把集合S中的子集合Root2并入子集合Root1中，要求Root1和Root2不相交。用森林表示就是一颗树的根结点加到另一棵树的根结点下，变成直接子结点，且只能对最高层做这个操作。
2. Find(S, x)：while(S[x]>0)x=S[x];return x，查找集合S中，单元素x所在的子集合。注意返回的是最高层结点，理想上所有子结点都是最高层的下一层就是最优的。
3. Initial(S)：将集合S中每一个元素都初始化为只有一个单元素的子集合。

常用一个一维数组的作为并查集的储存结构：值表示父结点的索引，初始化时全部赋值为-1，结点实际的值另外记录；合并时把Root2的值改为Root1的索引，Find时循环查找S[x]直到值为-1，返回索引。但这样没有路径优化。

另一种方式是初始化时S[i]=i，检查时当S[i]==i即表示最高层。这样在查找的时候可以把子结点移动到上面去，即路径优化。具体看：https://zhuanlan.zhihu.com/p/35314141

合并后集合中可以有重复元素。

## 二叉排序树(BST)

* 左子树所有结点 < 根结点 < 右子树所有结点，是一种递归结构。结点含有值，进行搜索比较时可以只和自己比，不用管左右是否为null
* 查找：返回结点而不是bool，因此如果当前不为null且不等于当前值才往左右走，否则直接返回当前即可
* 插入：如果为null就创建新结点，否则如果和当前相等就直接返回什么也不做，否则如果小于当前或大于当前就递归调用该函数
* 删除：删叶子结点什么也不用做，删度为1的结点就让子树成为父结点的子树。如果度为2，用左子树的最大(右)结点即中序线索前驱或右子树的最小(左)结点即中序线索后继移动填补，再实际删除它，原理是保持BST中序遍历与排序结果相同
* 与二分查找类似，但二分查找的判定树唯一，BST不唯一，不同的插入顺序会形成不同的BST。二分查找如果用来插入和删除，需要移动结点，而BST只要改指针即可。中序遍历BST可得有序序列，所以只需要再知道先序/后序就可画出整个BST了
* 查找效率主要与高度有关。可能出现一长条的情况，最坏是O(n)
* 最佳二叉排序树（高度最小）：先把数组排好序，然后按照左闭右开二分法构造。除了最下一层可以不满外，其他各层都是充满了的。是AVL树，但**不是完全二叉树**
* 对于删除某一结点又再插入它：如果本来是叶结点，则插入后与删除前树的结构相同；如果不是，则一定不同。AVL树完全没有这种说法，都是可能相同

### 平衡二叉树（AVL树）

* 左子树和右子树的高度之差的绝对值不超过1
* 左子树和右子树也是平衡二叉树
* 以上两个条件并没有说要左 < 中 < 右，因此有人认为AVL不属于BST
* 平衡因子：左子树高度-右子树高度。每个结点增加一个高度属性，叶子结点高度为1，插入和删除时更新高度，临时计算平衡因子
* 保证查询的时间复杂度是O(logn)
* 构建高度为h的AVL所需的最少结点数：N1=1, N2=2, Nh=1+N(h-1)+N(h-2)，所有非叶子结点的平衡因子都为1；图像上表示，就是每次迭代都给孩子未满的结点加一个子结点

#### 插入调整方法

* 每次只调整最小不平衡子树：插入后可能导致多个结点平衡因子绝对值大于1，但只需以最下面的那个绝对值为2的结点为基准
* LL平衡旋转（右单旋转）：在结点A的左(L)孩子B的左(L)子树C上插入了新结点X导致A失衡。需将A顺时针旋转移下一层，B升高一层代替原来A的位置，A变成B的右孩子，B的原右孩子变成A的左孩子，A和C变成兄弟，C和X不变。RR左单旋转：略
* LR平衡旋转（先左再右双旋转）：在A的左(L)孩子B的右(R)子树C上插入新结点X导致A失衡，需要进行两次旋转操作。先将C逆时针旋转到AB之间，此时A的左孩子变为C，C的左孩子变为B，C的原左孩子变为B的右孩子，X有可能跑到B的子树上，再对A按上一条右旋。RL先右再左：略
* 调整后的结点可能不是叶子结点：一开始根结点和左孩子两个结点，往左孩子的右孩子插入，平衡后就不是叶子结点了

另一种方法：

* LL/RR形：把中间的放到上面
* LRL/RLR形：把中间那个放到最上面去
* LRR/RLL形：把中间那个放到最上面去，但最后一个结点放到另一颗树上，否则不满足左边严格小于右边

删除：

* 如果是叶子结点，直接删除；如果有子结点，用其前驱或后继代替，实际删除它。向上递归到根，每一层沿着高度大的子树向下找三代，用上面的调整方法。

### 红黑树

* 结构改变小，所以红黑树一般可以做可持久化
* 插入是常数，删除也是常数，而AVL删除不是
* 适合插入多的情形，查找比AVL稍微慢
* https://blog.lilydjwg.me/2019/10/3/red-black-trees.214825.html

## 哈夫曼树

* 路径、路径长度、树的路径长度：见上文树的概念
* 权
* 结点的带权路径长度：从该结点到根之间的路径长度与结点上权的乘积
* 树的带权路径长度：所有叶子结点的带权路径长度之和，记作WPL
* 应用：两两合并多个有序表时，优先合并长度小的，因为每次都会把合并完的再遍历一遍。这就用到了哈夫曼树的构造思想

### 构造过程

1. 根据给定的n个权值构造n棵只有根结点的二叉树，n棵构成一个森林F
2. 在F中选取两颗根结点的权值最小的树作为左右子树构造一个新的二叉树，且权值为左右子树之和。
3. 在F中删除那两棵树，把新树加入F。
4. 重复(2)和(3)，直到F只含一棵树为止。
5. 构造时选中的两颗子树，先遍历到的为左子树。新构造的树放在末尾。

### 性质

* 权值越小，根到那个结点的路径长度越大
* 构造过程中新建了N-1个结点（度都为2），因此总结点数为2N-1，或用下面的公司也可以算
* 没有度为1的结点，因为每次构造都选两颗子树作为新结点的孩子
* 度为m的非二叉树哈夫曼树，仍然只有度为0和m两种结点。`N=N0+Nm=1+m*Nm，Nm=(n-1)/(m-1)，N0=Nm*(m-1)+1`

### 哈夫曼编码

* 哈夫曼编码是最优前缀编码
* 哈夫曼树又叫最优二叉树，是一种带权路径长度最短的树，不是唯一的，可以用来进行通信电文的编码和解码
* 从根出发到各个叶子结点，走左边生成0，右边生成1

## 图

### 基本术语

* G=(V,E)，V(G)为非空顶点集，E(G)为边的集；|V|为顶点的个数，叫阶
* 无向图：E={(1,2),(1,3)}。有向图：E=`{<1,2>,<2,1>,<v弧尾/起点,w弧头/终点>}`，从v指向w
* 简单图：不存在重复边、不存在顶点到自身的边。数据结构仅讨论简单图。反之如果两个顶点间的边数多于一条或者有与自己关联的边，则为多重图
* 完全图：无向图有n(n-1)/2条边，任意两个顶点之间都存在边。有向图有n(n-1)条弧，任意两个顶点之间存在方向相反的两条弧。用矩阵表示就是除对角线以外全部都是1
* 子图：略。不是任意V和E的子集都能构成G的子图，当E'关联了不存在于V'的顶点时，就不是一个图。如果V不变，E少了，叫生成子图
* 连通、连通图、连通分量：v到w有**路径**存在称为连通。每两个顶点都连通则为连通图。一个有n个顶点的图的边如果少于n-1，必为非连通图。**无向图**中的极大连通子图称为连通分量
  * 一个n个顶点的图，确保是无向连通图所需的最少边数：n-1个顶点构成完全图（非连通图的最多边数），再+1，即(n-1)(n-2)/2+1。
* 极大连通子图：连通子图略。连通图只有一个极大连通子图，就是它本身。非连通图**有多个**极大连通子图。极大是指此时把任意一个不在子图中的顶点并入子图都会导致这个子图不再连通（那个点和子图之间没有边）
* 强连通图和强连通分量：在**有向图**中，任意两个不同的顶点，Vi->Vj和Vj->Vi都存在**路径**（不是弧），则为强连通图。边最少的强连通图为一个环
* 连通图的生成树：一个极小连通子图，含有所有n个顶点但只有树必须的n-1条边，再加任意一条边就会产生环，不唯一
  * 一个无向图是树的条件：必须是无回路的连通图或者是有n-1条边的连通图（其实都是一个意思）
* 二分图：若无向图顶点集可分为两个不相交子集，且子集内部顶点之间没有边
* 度、入度、出度：无向图某一顶点边的数目称为它的度，有向图是入度加出度。有向图所有顶点的入度等于所有顶点的出度等于边数。所有顶点的度数之和等于边数的两倍，为偶数；度数为奇数的顶点的个数是偶数
* 权和网：边带上的数值就是权。带权图是网
* 邻接点：一条边的两个顶点相邻接/互为邻接点，边**依附于**那两个顶点
* 稀疏图和稠密图：没有准确定义，一般来说边数小于vlogv就是稀疏图
* 路径、路径长度、带权路径长度、距离：路径是两个顶点之间（含）的**顶点序列**，路径长度是路径的**边的数目**。最短路径长度称作距离，如果不存在路径，距离为无穷
* 回路/环：第一个顶点和最后一个顶点相同的**路径**。n个顶点的图有大于n-1条边则一定有环。若有向图中存在拓扑序列，则该图不存在回路
* 简单路径、简单回路：路径中的顶点不重复叫简单路径；除了最开始那个以外，顶点不重复，叫简单回路
* 有向树和有向森林：只有一个顶点的入度为0，其余顶点入度为1的有向图称为有向树

### 储存结构

* 邻接矩阵
  * 无权图有边为1，无边为0，对角线为0；有权图有边为权值，无边为无穷（代表距离）
  * 无向图沿对角线对称
  * 不利于增加和删除点、空间复杂度高
  * 一行代表那行顶点的出度，一列代表那列顶点的入度
  * 矩阵平方后的某个点的值代表从i到j顶点长度为2的路径有多少条
* 邻接表：表头：{data, firstarc}，边：{adjvex, nextarc}。不利于判断顶点之间是否有边，不便于计算顶点的度（主要是入度）。逆邻接表略
* 十字链表：仅用于有向图。弧：{tailvex弧尾的顶点, headvex弧头顶点, hlink弧头相同的下一条弧, tlink弧尾相同的下一条弧}，顶点：{data, firstin第一个指向它的弧, firstout第一个指出它的弧}。用于有向图，比邻接表更有利于获得指向自己的顶点。顶点可用顺序储存，则tailvex等的值是定点的索引
* 邻接多重表：适用于无向图，一条边只对应一个结点
* 对于一个图，邻接矩阵的表示法是唯一的，但邻接表不唯一，会根据输入顺序变化

### 遍历

* 非连通图无法一次就遍历完，只能访问包含那个顶点的连通分量。可以根据visited不重复地多次遍历，遍历次数就等于连通分量数
* 需要一个数组标识visited[]某个顶点是否访问过，长度与顶点数量相同
* 深度优先DFS、广度优先BFS：基本都一样，前者用栈或者递归，后者用队列。广度优先对应二叉树的层次遍历
* 空间复杂度都为O(V)。时间复杂度：邻接表法都为O(V+E)，邻接矩阵都为O(V^2)
* BFS其实能解决单源最短路径，因为它总是按照距离由近到远遍历图。但要边的权值相等
* 两种遍历都有生成树（非二叉树），非连通图是森林

### 最小生成树

* 生成树是n-1条边。最小指权值之和(代价)最小且唯一。所有权值最小的边不一定会出现在最小生成树中。各边权值不同时最小生成树唯一。存在权值相同的边时最小生成树也可能唯一（那些边权值太大去掉了）
* Prim算法：以一个顶点开始，重复在**未选定**且可以直接与**已选定的点集连接**的**点集**中选择距离最小的边和点。直到树包含全部顶点。时间复杂度O(V^2)
* Kruskal算法：最初把所有顶点每个都看作一个单独的树。按权值从小到大排列边，如果选择了某条边以后可以减少一个非连通分量（边的两个顶点属于不同的连通分量、不构成回路），则选择那条边以及两个顶点。直到没有非连通分量。时间复杂度O(ElogE)与顶点数无关，适合边稀疏的

### 最短路径

#### 迪杰斯特拉算法

1. 用于计算单源最短路径，边带有负权值时不能用，时间复杂度O(V^2)。如果要求其它点，每个都要算一遍。
2. （手算）写出图的邻接矩阵（二维数组），方便使用“跳板”时计算距离。
3. （可选）一维数组path[]存放（源点到）顶点k的（最短路径的）前驱，结束时可根据它追溯到源点求出最短路径。如果只求最短距离就不用这个。
4. 一维数组dist[]存放源点到其他点的距离/权值。初始化时只有与源点**直接相连**的点有值，不相连的为无穷；只有源点算作已求出的。
5. 剩余顶点集合。也可以用一个visited[]标记是否已求出最短路径。

操作步骤：

1. 初始化。
2. dist[]中**未被求出的最小的一项**即为源点到那一项的最短路径。
3. 以(2)中找到的那个点为“跳板”，更新源点到其他点的距离。即如果dist[k]>dist[j]+arc[j][k]，就赋值过去，且path[k]=j
4. 重复(2)、(3)。

#### Bellmon-Ford算法

1. 也是单源最短路径，可以处理负权边和负权回路，不是贪心算法。
2. dist[]同迪杰斯特拉算法
3. 进行v-1次循环，每次处理所有的边。若(源点到)边的起点距离+边的长度<终点距离，则更新。如果没有负权边且一轮下来都没更新，也可提前结束。每一轮相当于得到离源点i跳的最短路径。
4. 与迪杰斯特拉算法的明显区别是没有“确定好的源点到一部分已是最短路径的顶点”的集合。
5. 还有一种队列优化的SPFA算法，也能处理负权边，不能处理负权回路。

#### 弗洛伊德算法

1. 二维矩阵D[i][j]初始化时为顶点i到j直接相连的距离，不直连的为无穷。
2. （可选）二维矩阵path[i][j]保存j的最短前驱。当path[x][y]==x时表示顶点x到y直接连接（初始化时若相连则为此项）；path[x][y]==z时，表示z到y更短，此时再去找path[x][z]；等于-1表示不相连。
3. 每一轮选定一个顶点k作为跳板，把整个矩阵全部更新一遍（插点、松弛）：D'[i][j]=Min{D[i][j], D[i][k]+D[k][j]}，path[i][j]=path[k][j]（若后者更短）
4. 用于解决每对顶点之间的最短路径。时间复杂度为O(V^3)，允许带有负权边，也适用于带权无向图（看作有往返二重边的有向图）；但不允许有带负权回路。不是贪心算法。

### 拓扑排序（AOV网）

用于研究“先修课程”之类的问题，适用于有向无环图(DAG)。结果不唯一，时间复杂度O(V+E)。

1. 在有向图中选一个无前驱的顶点并输出它。
2. 从图中删除该顶点和所有以它结尾的弧。
3. 重复(1)、(2)，直至图不存在无前驱的顶点。此时除第四点外图为空。
4. 如果此时输出的顶点数小于有向图中的顶点数（图不为空），说明存在环。

按照拓扑排序的结果生成的邻接矩阵是三角矩阵；如果一个图的邻接矩阵是三角矩阵，则存在拓扑序列。

### 关键路径（AOE网）

* 用于估算完成整项工程至少需要多少时间、判断哪些活动是影响工程进度的关键。顶点称为事件，边称为活动。
* 网中只有一个入度为零的点，称为源点；一个出度为零的点，称为汇点
* 找一条从源点到汇点的带权路径最长的路径，称为关键路径；关键路径上的活动称为关键活动
* AOE的边带权，AOV仅表示先后关系

#### 求解方式

1. 求出每个**事件**的最早发生时间ve(i)=Max{ve(k) + w(k,i)}，是带权路径最长的路径。因为只有某个顶点所有的前继结点都完成时，此顶点的工作才能开始进行，所以最早发生时间是前面的最大值。
2. 根据(1)，从后往前求出每个**事件**的最迟发生时间vl(i)=Min{vl(k) - w(i,k)}：在所有后继事件的最迟发生时间减去路径长度的结果中选择最小值，即必须尽量“早”，不能影响任何一个后继的最迟发生时间。
3. 计算各**活动**的最早开始时间e(i)：活动`ai=<Vj,Vk>`的最早开始时间e(i)=ve(j)，即边的起始顶点的最早发生时间。
4. 计算各**活动**的最晚开始时间l(i)：活动`ai=<Vj,Vk>`的最晚开始时间l(i)=vl(k) - w(j,k)，即边的弧终点的最晚发生时间减去边的时间；不是起始顶点的最晚发生时间。
5. 找出e(i) = l(i)的活动ai，这些边即为关键活动，由关键活动形成的从源点到汇点的每一条路径就是关键路径。关键路径可以不止一条。
6. 做完1和2已经可以看出“关键事件”了。

## 查找

* 适合静态查找：顺序查找、折半查找/二分查找、散列查找
* 适合动态查找：BST、散列查找
* 平均查找长度ASL：所有关键字比较次数的平均值，或等于∑查找第i个元素的概率乘以找到第i个元素所需进行的比较次数；分为成功和不成功的
* 一般的顺序查找/线性查找：ASL成功=(n+1)/2，ASL失败=n+1
* 有序表的顺序查找：关键字有序，则查找失败时可提前退出；不要求随机访问，可以是链表。可用BST判定树描述，若有n个查找成功结点，则必相应有n+1个查找失败结点，**ASL成功与乱序一样**，ASL失败=n/2+n/(n+1)
* 折半查找：严书用的是闭区间，条件为low<=high；ASL成功约等于log(n+1)-1。只能用顺序存储。判定树是AVL，但在某些计算时却当作完全二叉树，如认为树的高度是log(n+1)向上取整，且查找失败时的最多比较次数就是树的高度，最少比较次数是高度-1因为不一定是满树
* 失败ASL的求解方法：画出方形的虚构失败结点，**但到达它的查找长度等于到实际存在的那个结点的长度（虚构结点的父结点）**，只是加的次数和最后除以的次数按失败结点的数量来
* 分块查找/索引顺序查找：顺序和折半的结合，提供一个关键字有序的索引表，块内可无序但块之间有序，一个块的关键字是本块中最大的，且小于任何下一个块的值

### B树/B+树 多路平衡树

* 定义和性质
  * 所有孩子结点中分支最大值称为阶，是预定义的，用m表示
  * 关键字：大于左孩子，小于右孩子
  * 每个结点至多含有m-1个关键字，m个孩子
  * 若根结点不是终端结点，则至少有两棵子树
  * 除根结点以外的所有非叶结点至少有m/2向上取整棵子树
  * 所有叶结点在同一高度上，所有结点的平衡因子都为0，不包含任何信息，实际上不存在，代表查找失败
  * 相比于红黑树等二叉树，数据量大时高度更矮
* 查找：B树无法顺序查找，而B+树可以，因为后者叶子结点之间连起来了，而前者数据分布在整个树中
* 插入：最初一定是插入到最底层的某个非叶结点内，如果该结点的关键字个数大于m-1，必须进行分裂，把中间部分的移到父结点中，递归进行
* 删除（关键字）
  * 不在底层：如果在中间，合并中间的孩子；否则就把前面或后面的一个子结点（前驱/后继）提到自己这一层，然后递归往下删除
  * 在底层：在当前结点中，关键字个数大于等于m/2向上取整就直接删，否则看兄弟够不够借，够就把兄弟提到父关键字，原父关键字往下移；不够就直接把父结点往下移
* B+树
  * 子树个数与关键字个数相等，关键字的值等于孩子中最大的
  * 只有叶结点包含信息，非叶结点仅起到索引作用
  * 所有相邻叶结点连接到下一个
  * 通常有两个指针，一个指向根结点，另一个指向关键字最小的叶结点
  * 时间复杂度更稳定，遍历范围更方便

### 散列表

* 散列函数和散列地址
  * 直接定址法: H(key)=key或a*key+b，地址集合要和关键字集合一样，不会发生冲突，但空间需求太大，意义不大
  * 除留余数法: H(key)=key%p，最好选择不太接近2的整数幂的素数，且小于数组长度m
  * 乘法散列法：key乘以小于1大于0的常数A，提取小数部分，乘以m，向下取整；A建议用(√5-1)/2==0.618033
  * 数字分析法、平方取中法、折叠法、全域散列法
* 冲突处理方法
  * 开放定址法(open addressing)
    * 也被称作封闭散列(close hashing)，每个哈希项仅储存一个值，储存前必须探测是否已存在，存在则需要重新计算
    * 线性探测法：找下一个。Hi=(H(key)+i) MOD m（注意不是上文的p）。当Hi==H(key)时表示满了，探测失败
    * 二次探测法/平方探测法：一般依次找两边的1、4、9...位置。Hi=(H(key)+c1i+c2i^2) MOD m。当探测到(m/2)^2还没找到位置则探测失败
    * 双重散列法：第一个发生冲突时利用第二个散列函数计算增量。Hi=(H1(key)+i*H2(key)) MOD m，且H2产生的数必须与m互素，当m为素数时保证Hash2更小即可
    * 再散列法
    * 伪随机序列法
  * 链地址法/拉链法：把具有相同散列地址的记录(同义词)放在单链表中；其实属于开放散列(open hashing)，也可以用树；同一哈希储存多个值，无需探测
  * 公共溢出区
* 在开放定址的情形下，不能随便删除表中已有元素，只能给它做个标记表示逻辑删除。因为找到空的地方就算不存在了，但可能它后面存在未被删除的元素。因此需要定期维护
* 把不同关键字映射到同一地址称作冲突，这些关键字称为同义词。不正确的处理冲突的方法会导致聚集/堆积，会影响ASL；也可说同义词之间或非同义词之间发生冲突导致堆积
* 平均查找长度ASL
  * 成功的：查找到各个数据所需查找次数之和/元素个数（假定每个关键字的查找概率相同）
  * 失败的：根据上文的p，依次计算[0,p)所在位置到空时所需查找次数之和，再除以p。与存了哪些数据无关
* 装填因子α：表中记录数/散列表长度，显然越小越好
* 正常来说元素是不会重复的，但根据题意也许可能重复（南大842）

## 排序

* 插入类：直接插入、折半插入、希尔排序
* 交换类：冒泡排序
  * 快速排序：平均需要O(logn)的递归栈空间，时间复杂度最坏O(n^2)，如果用严书的方法就发生在基本有序的时候
* 选择类：选择排序、堆排序：都不稳定，都与初始序列状态无关
* 归并类：归并排序，时间复杂度总是O(nlogn)，空间O(n)，稳定
* 分配类：桶排序、计数排序(特殊的桶排序，空间复杂度O(r)，时间复杂度O(n+r)，r是数字范围)
  * 基数排序：不是基于比较，而是用多关键字排序的思想；先把所有数按个位排序，再排十位百位；不能用于小数
* 外部排序：多路平衡归并、置换-选择排序、最佳归并树
* 排序算法的对比：时间复杂度（最好、最坏、平均）、空间复杂度、稳定性；其它影响因素：待排序的元素数量、元素本身的信息量
* 直接插入和冒泡最好复杂度(已排好)为O(n)且不需要交换；选择排序时间复杂度总为O(n^2)，但如果元素本身大，更少的交换次数是优势；直接插入和选择排序的排序趟数都为n-1，与原始序列状态无关，而冒泡有关；直接插入的元素移动次数与序列状态有关，冒泡也有关
* 将两个长度为N的有序表合并，最少的比较次数是N，此时一个表的最小元素比另一个表的最大元素还大；最大的比较次数是2N-1，此时两个表中的元素是依次间隔地比较
* 任何基于比较的排序方法最坏至少需要O(nlogn)的时间
* 除了快排、归并排序、基数排序以外，空间复杂度都为O(1)

### 希尔排序/缩小增量排序

以49, 38, 65, 97, 76, 13, 27, 48, 55为例子。若取d1=4，则所有间隔为4的记录在同一组：(49, 76, 55)、(38, 13)、(65, 27)、(97, 48)，它们内部排序。第二趟取d2 < d1，重复上面的排序，直到d=1。此时变为普通的插入排序，但之前的操作加快了最后一次排序的速度。仅适用于顺序表，不稳定。时间复杂度O(n^1.3)

### 堆和堆排序

* 在序列对应的树中，当每个元素都大于它左右两边的元素时，它就是一个大顶堆；或者每个元素都小于它左右两边的元素时，它就是一个小顶堆
* 堆是一个完全二叉树，既是BST又是堆的树只有根结点和根结点加左孩子两种
* 向下调整(AdjustDown/sink)：查看自己是否比两个孩子都大，如果不是，把自己与更大的那个交换。并继续对交换后的自己向下调整（因为调整后子堆也可能破坏了）；做一次的时间复杂度是O(h)即O(logn)
* 向上调整(AdjustUp/swim)：若自己大于父结点，把父结点与自己互换。并继续对交换后的自己向上调整
* 插入：直接把它添加到最后一项，然后向上调整
* 删除：将最后一个元素和堆顶交换，堆的大小减一，然后对堆顶向下调整
* 初建堆：从n/2往前对每个元素向下调整。因为n/2之后是叶子结点，已经算合法的堆了。复杂度是O(n)
* 堆排序算法：先建堆，然后和删除元素一样；只会用到向下调整。大顶堆排序后是从小到大的。最好最坏平均时间复杂度都是O(nlogn)，空间O(1)，不稳定
* 可用于得到无序序列中k个最小元素（Top K），只需建立k个元素的大顶堆，当新元素比堆顶更小就替换并调整；不是全部小顶堆建完再排k次；有序的用二分更好。可用来做优先队列，在大顶堆上加Increase函数，不允许减小值
* 堆是用来排序的，在查找时它是无序的
* 调整时都是非相邻的元素，缓存不友好
