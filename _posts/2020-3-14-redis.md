# Redis

## 特点

* 内存数据库，单条操作具有原子性
* 五种基本类型：String、Hash、List、Set(无序、元素唯一)和ZSet有序集合，每种数据类型都有丰富的操作命令，后四种每个可有2^32-1个成员
* 与memcached的区别：m只支持简单的字符串，且无法持久化；多线程
* 支持多个db，每个数据库的数据是隔离的，不能共享，使用SELECT指令切换，从0开始，默认到15。只有单机才有，集群没有；FLUSHALL可清空一个实例的所有数据库。因此它更像一种命名空间，不同应用应使用不同的redis实例
* ACID：A指一组操作，要不完成，要不没做，不存在改了一半的状态，没完成的操作可以回滚。Redis的事务不支持回滚，没有原子性，只支持Isolation
* 保存数据时的后台IO一直有多线程，6.0的网络有多线程

### 适合场景

* 缓存热点数据
* 排行榜：ZSet
* 计数器、限速器
* 共享Cache，不怕丢数据，丢了可以从DB中reload
* 共享Session，不怕丢数据，丢了可以重新登录
* batch job的中间结果。不怕丢数据，丢了重新跑job就可以了
* 集合运算，如共同好友
* 一些简单数据的存储，低频改动，但是会被频繁读取。比如首页推荐的产品列表。但此时必须增加HA的防护，sentinel、cluster或者自定义的机制都可以
* 一些更加复杂存储的building block，比如分布式锁，此时需要多节点来实现一个简单的quorum

#### 消息队列

* 容忍小概率消息丢失，通过定时任务/手工触发达到最终一致。消息堆积概率低，有相关的报警监控
* PUB/SUB即发布-订阅模式：生产者和消费者是1-M的关系，一条消息会被多个消费者消费，解决的是广播的问题。消息会在当时就处理并删除，如果当时没有订阅，消息不会留着。没有ACK
* PUSH/POP：没有ack机制，消息取出后消费失败依赖于client记录日志或者重新push到队列里面
  * 改进：先BRPOPLPUSH到另一个列表中，成功处理后LREM，添加监视程序每一段时间把另一个列表中的放回原队列中因为它们代表失败，但这又可能出现重复消费的情况，因此要实现幂等性，保证重复消费结果一致。但消费者不支持集群，可以接收但无法LREM，改成SET好像可以
* Redis Stream

### 需要考虑的问题

* Redis-RDB半持久化模式下，非实时，存在不一致性。如果断电丢失一些数据，程序能不能接受
* 内存成本也要考虑在内
* 冷数据不要放
* 数据类型是否适合
* Value尽可能小
* 使用Pipeline或Lua Script
* 缓存穿透：不断查询不存在的数据；解决办法：接口层增加校验、确实不存在时对key写null，防止反复用同一个
* 缓存击穿：热点数据过期
* 缓存雪崩：过期时间随机设定，防止同一时间大量数据过期

## 安装

* Win版，非官方
  * https://github.com/redis-windows/redis-windows 依赖msys-2.0.dll，且还依赖另两个其他项目不依赖的msys dll，估计是TLS要用
    * https://github.com/hemnstill/StandaloneTools
  * https://github.com/CacoCode/LeadingCode.RedisPack/tree/master/attrs
  * https://github.com/icetech233/windows-msys-redis 7.0.5
  * “因为MSYS2的规定，我们的软件必须至少要放置在2层目录文件夹内才可以正常运行，如d:/redis/dist/bin/可以，d:/redis/则不可以”
  * https://www.memurai.com/get-memurai 闭源，win下的兼容实现，每10天要重启，可安装为服务
  * https://github.com/tporadowski/redis 到5.0，是Native的，安装msi后就自动启动了服务
  * https://github.com/zkteco-home/redis-windows 要求使用者点Star，是Native的不是用MSYS构建的，闭源，允许安装为服务
* apt install redis-server。只装cli用redis-tools
* redis-server /etc/redis/redis.conf 必须指定配置文件
* redis-benchmark -n 10000 -q 性能测试，同时执行一万个请求
* redis-cli -h host -p port -a(auth) passwd。默认不加参数自动连本地的。ctrl+u清除输入
  * 也可用nc localhost 6379

### 编译

* gcc make pkg-config python3 binutils，测试要tcl，CYGWIN要libiconv-devel和libintl-devel
* make distclean; make -j2 CFLAGS="-DUSE_PROCESSOR_CLOCK"
* Msys2: `sed -i 's/__GNU_VISIBLE/1/' /usr/include/dlfcn.h; sed -i '/getTimeZone(void)/a return timezone;' src/util.c` CFLAGS=-Wno-char-subscripts 复制msys-2.0.dll
* 调试版：make V=1 noopt

## [配置](https://redis.io/docs/management/config-file/)

* Config Get */name：获取配置项
* Config Set name value：临时设置配置项，只有一部分可以用此命令动态设置，value为""会消掉name
* Config Rewrite：把Set的保存下来
* apt装的会创建`/etc/redis/redis.conf`，里面已经做了一些配置，注意不加参数地运行redis-server并不会使用该文件
* enable-protected-configs默认启用，使得部分不常更改的设置禁止在运行时更改

```conf
bind 127.0.0.1 -::1 # 不加时为全部，减号表示绑定失败也没事。另外默认启用了保护模式，当也没有设置密码时只会接受本地连接
#port 6379
unixsocket /run/redis/redis-server.sock
# 还支持启用TLS1.3

daemonize yes # 默认no，使用systemd时无意义。Win下有效
supervised auto # 对systemd的支持，默认no
pidfile /run/redis.pid

loglevel notice #【默】
logfile /var/log/redis/redis-server.log # 或用syslog-enabled。前台使用时不应设置

maxclients 10000 #【默】Win下实际最多大概3200
timeout 0 #【默】客户端空闲多久后关闭连接。0表示禁用超时
tcp-backlog 511 #【默】还受内核影响
tcp-keepalive 300 #【默】每300秒发送保活信息

io-threads 4 # 建议遇到性能问题时设为核心数-1，超过8意义不大。仅在输出给客户端时使用，还有个io-threads-do-reads也对读启用但官方说一般没用
activedefrag yes # 自动整理内存碎片。如果没有遇到碎片问题则不需要开启
list-compress-depth 1 # 当一般仅访问List的首尾时压缩其余部分
lazyfree-lazy-user-del、lazyfree-lazy-user-flush yes # 将Del改为Unlink的行为、Flush改为异步
latency-tracking no # 默认开启因为消耗很小。查看数据用INFO latencystats

requirepass passwd # 设置密码。Redis6后使用了ACL机制管理用户、密码、允许执行的命令
```

### 淘汰策略

* 配置：maxmemory 100mb 包括临时缓冲区在内的总大小，主从复制时尤其考虑。maxmemory-policy 见下。active-expire-effort在后台用多少CPU主动检测过期数据
* volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰
* volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰；如果ttl一样就选最近最少使用的
* volatile-random：从已设置过期时间的数据集中任意选择数据淘汰
* volatile-lfu：从已设置过期时间的数据集中选择最近最不常用的数据淘汰
* allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰
* allkeys-random、allkeys-lfu：略
* no-enviction：【默】不淘汰数据，如果内存不够就报错，仍可读。Active-Active Geo-Distributed CRDBs一直用此项
* lfu与lru的区别：当执行淘汰时假如一个不常用数据最近刚好用过，那lru下可能会淘汰另一个常用但最近没用过的数据；但lfu资源消耗更大一点
* 设置volatile系时，如果没有过期的，内存又满了，还是会报错

### 持久化

* RDB方式文件紧凑，适合隔一段时间持久化保存，恢复速度相对快；因为是隔一段时间保存的，可能丢失数据
  * 后台异步保存时会fork和COW，如果宿主机内存不够可能会失败，但其实不会消耗很多内存，可用`echo 1 > /proc/sys/vm/overcommit_memory`
* AOF方式默认每秒fsync且性能仍不错，因此最多丢失一秒的数据（主从复制时还可能丢两者未同步的）；当文件过大时会自动重写压缩（或手动用BGREWRITEAOF）不过仍比RDB大一些，在处理巨大的写入载入时性能差一些
  * 复制备份aof文件时可能因为正在重写而失败，应先暂停
* 两者可以同时启用，此时默认用AOF进行恢复
* 启动redis-server时会自动读取持久化的数据，如果数据太大就会花很久
* 如果AOF也损坏，可备份原有文件，用redis-check-aof进行修复，用diff -u对比

```conf
save 900 1  # 900秒内有一次改动就save
save 300 10 # 指令可多次使用
save 60 10000
# save "" # 表示关闭RDB。默认为上面三条启用
dir /var/lib/redis # RDB和AOF写入的文件夹。若用相对路径则是相对于CWD的，不设置时为CWD
dbfilename dump.rdb

appendonly yes # 默认关闭
appendfilename "appendonly.aof"
appenddirname "appendonlydir" # Redis7会生成多个aof文件，放在单独的文件夹里
appendfsync everysec #【默】
no-appendfsync-on-rewrite yes # 若fsync()被阻塞而有延迟，启用此项相当于某些时候的appendfsync no
aof-timestamp-enabled yes # 老版本无此项，启用后若要用外部工具分析aof时也许会不支持
```

### 主从复制

* 树状：m-s1、m-s2。链状：m-s1-s2
* slave默认只读
* 如果没有开持久化，那也不要开自动重启，否则M重启后会把空的复制过去

```conf
replicaof <masterip> <masterport> # 作为slave连接master
masterauth <master-password>
replica-serve-stale-data yes # 当slave失去连接时是否继续响应请求
shutdown-timeout 10 # 关闭时等待从的最长时间
```

#### 哨兵模式

* 监控master和slave是否正常运行，以及哨兵之间也会相互监控。当master挂了，会自动选一个slave作为master顶上去，原master后续如果恢复了会自动变为slave。只用于监视和故障转移，不负责主从复制
* 最小架构：三个可用区，一个Master，两个Replica，分别再在每个可用区里加一个哨兵
* 配置文件：`sentinel monitor 任意名字 主节点ip 端口 2`。运行redis-server时加--sentinel，一些其它配置会自动生成。最后一个值表示有几个哨兵认为主节点挂了才切换。只要写Master的ip；可以监视多个不同的redis实例
* 端口默认26379。Jedis在使用时传入那些哨兵的地址，从那里得到master节点
* 如果运行在docker里，要特别设置announce-ip和port

#### 集群模式

* 用于横向扩展容量。节点都是master，每个负责一定范围的slot
* 创建：cluster-enabled yes。redis-cli --cluster create 节点地址1 地址2。也可以再给master配slave，用--cluster-replicas 1表示每个m配一个s
* 使用：redis-cli -c。不加-c时如果连接的节点不负责那个key，会返回error和负责那个key的地址
* cluster nodes查看集群节点信息

## [指令](http://www.redis.cn/commands.html)

* 指令可小写，输入时自动有提示
* 返回值：对于动作，一般成功返回1，失败返回0，或者成功返回OK，失败返回nil；Incr返回变化后的值，Append返回字符串长度，HSet成功覆盖已存在的值也会返回0，此时0和1表示是否是一个新字段
* 索引范围都是闭区间，负数可以从后往前计数，`0 -1`就覆盖所有
* 超出范围的索引不会产生错误：如果from大于集合的最大索引或大于to，会返回空列表；如果to大于集合的最大索引，会返回直到最后一个
* -inf或-表示负无穷，+表示正无穷
* 不同指令拥有不同属性：`WRITE`表示会修改数据库，`DENYOOM`表示有可能增加储存空间（显然拥有该属性的指令都拥有`WRITE`属性），`NOSCRIPT`无法在脚本中执行，`RAMDOM`当一个脚本执行了该属性的命令后就不能再执行`WRITE`属性的命令了；还有两种略

### String

* 其实值可以放任何数据，只要序列化成二进制就行，不能超过512M

```redis
Set k1 "foo" # 引号不必须除非有空格；默认重复set同一key会直接覆盖；EX指定过期时间，或用SetEX；NX/XX指示当KEY不存在/已存在时才set，前者还可用SetNX，可当作分布式锁
MSet k1 v1 k2 v2 # 同时设置多个
Get k1 => "foo" # MGet同时查询多个，返回一个列表
Exists k1 => 1 # 不存在时返回0
Keys */pattern # 查询所有/指定的key，支持：?、*、[]、[^]、[a-b]、反斜杠转义。数量多时应用SCAN。RANDOMKEY随机返回一个key
Incr/Decr k1 # 自增/自减不存在的key会自动从0开始，只适用于“数字”，实际类型还是string
Incrby/Decrby k1 10 # 加/减10；浮点用IncrbyFloat，不存在DecrbyFloat，可加负数代替
GetRange/SetRange：相当于操作字符数组，Get需指定start和end，Set指定offset
Append：字符串末尾附加，如果key不存在会自动创建
GetSet：设置并返回原值
Rename、RenameNX、Strlen、MSetNX、Del：略。Unlink：异步的Del
```

### Hash

* 当**字段**较少时会自动用O(N)的数组不用哈希表，这样缓存命中好
* 对应object/model的用法，但不能嵌套
* 另一种用法是有大量小型数据时把key分成两半，这个当作二级哈希表
* `:1000`就是字符串的一部分，不特殊，类似于普通语言的点，此处是用作id

```redis
HSet user:1000 name "John Smith" # 字段无法单独设置过期时间
HMSet user:1000 email xxx passwd xxx # 4.0后HSet就也能这样做了
HGet user:1000 name
HGetAll user:1000 # 获取所有的字段和值；HKeys和HVals分别获得所有的的字段和值；HLEN获得字段数量
HIncrBy、HIncrByFloat、HDel、HKeys、HSetNX、HMGet、HExist：略
```

### List双链表

```redis
LPush/RPush mylist val1 val2 # 如果key不存在会自动创建，返回List的长度；LPushX当key存在时什么也不做
LIndex：取出指定索引的元素；LSet：在指定索引设置值
LRange mylist [from] [to]：相当于Slice/取子序列，`0 -1`能获取所有；LTrim：原地Slice，仅保留范围内的值
LLen：List的长度（第一个L不是Left）
LRem mylist [count] [val]：count大于0则从头往后搜索，移除数量等于count且值等于val的元素，小于0则从后往前，等于0则不限数量
LInsert mylist BEFORE/AFTER pivot value：在指定元素前/后插入
LPop/RPop：取出，如果没有元素会返回nil；BLPop：如果列表没有元素，会阻塞直到超时或发现可弹出元素为止；LPushX：列表已存在才添加值；RPopLPush：把值移动到另一个列表，可以是自己，有阻塞版
```

### Set无序集合

* 添加删除查找的复杂度都是O(1)，添加同一成员会失败

```redis
SAdd myset member1 member2 # 返回成功添加的个数
SMembers myset # 获取所有成员
SIsMember myset member1 # 成员是否存在集合中
SRem myset member2 # 删除成员
SPop myset 2 # 随机返回并移除两个成员；SRANDMEMBER是随机返回但不移除，但可能返回相同的
SUnion myset1 myset2 # 并集；SInter交集，SDiff差集；SDiffStore：把结果储存到另一个集合中
SCard：集合中元素的数量；SMove：移动成员到另一个集合
```

### ZSet有序集合

* 成员唯一，评分可重复
* 默认按评分从小到大排，分一样就按字典顺序
* 使用跳表

```redis
ZAdd myzset score1 member1 s2 m2 # score是double的
ZRange myzset [from] [to] [WITHSCORES]：按排名取范围查询成员；ZRangeByScore：按评分取范围；ZRevRange：从大到小排；ZRangeByLEX：按字典顺序进行排序，有点复杂
ZRank：查询指定成员的排名，评分最小的是第0名；ZScore：查询指定成员的评分；ZCount：查询指定评分范围内的成员有多少
ZRem、ZRemRangeByScore/Rank/LEX：移除成员
ZAddNX、ZIncrBy、ZPopMax、ZPopMin、ZCard：略
```

### 位图(位数组)

* GetBit/SetBit：见GetRange
* BitCount：设为1的数量
* BitPos：查找第一个值为指定值的位置
* BitOp：位运算
* BitField：支持许多子命令，对一个字符串进行按位运算

### HyperLogLog

* 基数统计：比如数据集 {1,3,5,7,5,7,8}，那么这个数据集的基数集为{1,3,5,7,8},基数(不重复元素)为5。基数估计就是在误差可接受的范围内，快速计算基数
* 用于计算日活用户(uv)
* PFAdd
* PFCount
* PFMerge：把多个合并到一个

### 事务

* Multi开启。之后运行命令不会返回OK，而是返回QUEUED
* Exec提交，中间不会插入其它连接的指令。如果出现错误，已执行的仍有效
* Discard取消
* Watch x 执行后如果exec前x变化了，则返回(nil)表示失败

### Stream

* 只读、只附加。可以被多个消费者读取。只是一种数据结构，与分布式无关
* XAdd stream名(key) * k1 v1 k2 v2 星号表示自动生成id，后面的部分与Hash类型类似。id是x-y样式，x是毫秒，y是同一毫秒内的流水号
* 订阅：XRead BLOCK 0 STREAMS key $ 无限期等待读取最后一个消息，下一次调用将美元符号改成处理完的id
* 读取指定区间：XRange或XRead的非阻塞模式，两者差不多。其中XRange用-表示最小的（也可用0），+表示最大的（非常大的数，而$表示那个stream的最后一个id）。COUNT不指定时默认为无限。XRead可以同时读取多个stream
* 消费者组：可以自动读取下一个id。需要消费者确认，服务端有“已发送未确认队列”，如果消费者挂了重启，会收到未ACK的消息。如果没有重启，其它消费者可以手动从“死信队列”中取出消息处理

### 其它指令

* 管道Pipeline，减少RTT：`$(printf "PING\r\n SET runoobkey redis\r\n GET runoobkey\r\n INCR visitor\r\n"; sleep 10) | redis-cli`
* 客户端缓存：如客户端订阅某个key，当值发生变化时由服务器通知订阅者，具体的缓存逻辑仍由客户端处理

```redis
Type：获得指定key的类型
Expire：设置超时秒数，负数和0效果一样；用PRESIST指令才能设置永不过期；ExpireAT：以Unix时间戳设置过期时间
TTL：查询剩余超时时间，-1表示永不过期，-2表示不存在
PExpire/PTTL/PSetEX：以毫秒为单位
Dump：序列化指定key的val，带有校验和；Restore恢复
Shutdown：保存并关闭server，和在bash中的kill服务端效果相同；Save：把数据保存到rdb中，BgSave：异步保存；恢复数据：把rdb放到Config Get dir中即可，BgRewriteAOF：异步写AOF；Auth：验证密码，Quit：退出当前cli，Time：返回服务器当前时间
Ping：返回PONG或者Ping的参数
Scan、HScan、SScan、ZScan：使用glob模式进行匹配，Scan匹配Key，SScan匹配字符串的值。默认一次返回10个，使用后会返回一个数字，作为下次的游标的值继续迭代，初始用0
Client List/SetName/GetName/Pause/Kill：其中暂停是以毫秒计挂起(阻塞)客户端，Kill是关闭指定连接；这些命令是操纵其它客户端连接的
MSETNXINCR/DECRGETSETDEL
Info [memory]：显示状态和设置
Memory doctor：显示内存问题报告、Latency doctor
Memroy purge：手动整理内存碎片，会阻塞主进程
Move：把key移动到另一个db中；SwapDb：把两个数据库名字互换
DbSize：Key的数量
FlushDb：清空当前数据库；FlushAll：清空所有数据库。都有ASYNC选项
Monitor：在客户端持续显示服务端之后执行的所有命令。当要下线redis节点时用它确保那个节点没有活动了
```

## [redis-py](https://github.com/redis/redis-py)

```py
import redis  # 异步：from redis import asyncio as aioredis
r = redis.Redis(host='xxx', port=xxx, protocol=3, decode_responses=True) # 不加任何参数自动连本地。默认已用连接池。默认不自动解码，返回bytes
r = reids.from_url('redis://user:pass@ip:6379/0?protocol=3') # 无密码时也要留@。TLS用rediss，还有unix
r.set('foo', 'bar')
r.get('foo')
r.mset(dict)
r.mget(list)

pipe = r.pipeline()
pipe.xxx().xxx().execute()
pipe.reset() # 或用with
```

## 其它

* 7.0：RedisFunctions、Sharded-pubsub(集群下使用避免广播风暴)
* RedisRaft：6.2，分布式强一致性模块
* RedisJSON
* RediSearch：全文搜索
* KeyDB：Redis的Fork，100%兼容，但对多线程优化
* dragonfly：兼容redis（到5.0）和memcached，在单机上比redis更好
* FerretDB：以PG为后端的MongoDB替代品
* 官方GUI：https://redis.com/redis-enterprise/redis-insight/ 开源但下二进制必须在官网填表格
* pika：国产(360)，完全兼容Redis协议，持久化存储 https://github.com/OpenAtomFoundation/pika/blob/unstable/README_CN.md
* disque：redis之父没有完成开发的消息队列模块，不要使用

## 参考

* https://www.zhihu.com/question/19660689
* https://zhuanlan.zhihu.com/p/96204110
* https://www.runoob.com/redis
* https://redis.io
* https://www.cnblogs.com/xiaohuiduan/p/11394505.html
* 《redis入门指南》

### TODO

* https://redis.com/glossary/
* https://zhuanlan.zhihu.com/p/469102289
* https://climbtheladder.com/10-redis-key-best-practices/
* 心跳，防止tcp长期不用被防火墙断了
* https://www.zhihu.com/question/20795043
* https://www.zhihu.com/question/51634494
