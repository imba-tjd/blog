# AI

## 模型

* LLaMA系榜单：https://ollama.com/library 选MostPopular
* 排行榜
  * 英文：https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard 可以筛选大小。https://www.vellum.ai/llm-leaderboard
  * 中文：https://cevalbenchmark.com/static/leaderboard_zh.html https://www.superclueai.com/
  * 代码：https://paperswithcode.com/sota/code-generation-on-humaneval
* 英文（应选基于它们的微调版）：Mistral-7B-Instruct-v0.2（mistral-openorca还没更新，现在有Mistral-7B-Instruct-v0.2-DARE）。小模型：phi-2
* 中文：XuanYuan-6B、BlueLM-7B、Qwen1.5-7B、Baichuan2-7B-Chat、Yi-6B、Chinese-LLaMA-Alpaca-2（1较差，2无测评）。小模型：MiniCPM-2B
* 代码：deepseek-coder、dolphin-2_6-phi-2
* 较差：tinyllama、gemma
* 选好后找其他人转换的GGUF版本，下Q5_K_M或Q4_K_M，主要靠 https://huggingface.co/TheBloke
* 原始模型只是续写。Instruct版每个模型有不同的prompt模板，不过基本分为ChatML和Alpaca两种。Chat版无需模板

## GUI

* https://jan.ai/ 开源桌面版本。导入后在Model和Assistant的三个点处修改全局设置
* text-generation-webui
* https://github.com/h2oai/h2o-llmstudio 开发比较初期但有公司支持
* https://lmstudio.ai/ https://faraday.dev/ https://msty.app/：闭源
* gpt4all：不能选本地下载的

## llama.cpp

* 纯CPU推理，下avx2版本
* python绑定提供py api和作为兼容OpenAI API的WebServer。或用https://github.com/mudler/LocalAI
* 运行：./main -m 模型.gguf -p "prompt"
* 交互模式：--interactive-first -r "[User]" -p "[System]You are a helpful assistant." --in-prefix "[User]" --in-suffix "[AI]"
* -n要输出的token数，默认-1无限适合Chat
* -c context length不同模型不同，默认512，llama2可用4096
  * --keep 保留最初的token数
* --color 用不同颜色区分用户输入和模型输出
* -t 要使用的线程，似乎默认等于当前CPU线程数且最大10，推荐改为物理核心数
* --prompt-cache cache.bin 缓存最初的状态加快启动
* -f 从文件中读取prompt
* --temp 0.8、--top-p 0.9 【默】调小会更保守，调大会有创意。一般只调其中一个。如对于答案是唯一确定的场合temp应用0.3
* --repeat-penalty 1.0即禁用 --no-penalize-nl 作者说对于Chat模型不应启用重复惩罚
* 另一款支持HF模型的聊天工具：https://github.com/foldl/chatllm.cpp

## PromptEngineering

* https://github.com/dair-ai/Prompt-Engineering-Guide
* https://github.com/f/awesome-chatgpt-prompts https://github.com/PlexPt/awesome-chatgpt-prompts-zh
* https://learnprompting.org/zh-Hans/docs/intro
* In the context of xxx, 实际问题

## 微调

* LLaMA-Factory
* QLoRA：适合小内存
* SFT(Supervised Fine Tuning)
* https://datasciencedojo.com/blog/fine-tuning-llms/
* 一般能单独输出微调的部分，之后与基础的合并，方便已有基础镜像的人快速获得微调后的

## HF镜像

* https://hf-mirror.com
* https://modelscope.cn/models
* https://aliendao.cn
* https://gitee.com/modelee
* https://aifasthub.com/
